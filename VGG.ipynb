{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rbjeAPI5qu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip uninstall -y kaggle\n",
        "!pip install kaggle==1.5.6\n",
        "!kaggle competitions download -c fcis-sc-deeplearning-competition\n",
        "!unzip /content/fcis-sc-deeplearning-competition.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKehPnUJqPT8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!unzip  '/content/drive/My Drive/test.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ujo8IbpC50WO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import ResNet50\n",
        "from keras.applications.vgg19 import preprocess_input\n",
        "from keras import Model, layers\n",
        "from keras.models import load_model, model_from_json\n",
        "import tensorflow as tf\n",
        "import PIL\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.resnet50 import preprocess_input\n",
        "import numpy as np\n",
        "from keras import applications\n",
        "import pandas as pd\n",
        "from keras.models import load_model\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from random import shuffle\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import tflearn\n",
        "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
        "from tflearn.layers.core import input_data, dropout, fully_connected\n",
        "from tflearn.layers.estimator import regression\n",
        "\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import *\n",
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "img_width, img_height = 256, 256\n",
        "\n",
        "TEST_DIR = '/content/val/val'\n",
        "TRAIN_DIR = '/content/train/train'\n",
        "VAL_DIR = '/content/test'\n",
        "\n",
        "\n",
        "\n",
        "nb_train_samples = 3138\n",
        "nb_validation_samples = 772 \n",
        "\n",
        "batch_size = 32\n",
        "epochs = 50\n",
        "\n",
        "\n",
        "\n",
        "model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
        "for layer in model.layers[:5]:\n",
        "    layer.trainable = False\n",
        "\n",
        "#Adding custom Layers \n",
        "x = model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(1024, activation=\"relu\")(x)\n",
        "predictions = Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "# creating the final model \n",
        "model_final = Model(input = model.input, output = predictions)\n",
        "\n",
        "# compile the model \n",
        "model_final.compile(loss = \"categorical_crossentropy\", optimizer=SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
        "\n",
        "# Initiate the train and test generators with data Augumentation \n",
        "train_datagen = ImageDataGenerator(\n",
        "rescale = 1./255,\n",
        "horizontal_flip = True,\n",
        "fill_mode = \"nearest\",\n",
        "zoom_range = 0.3,\n",
        "width_shift_range = 0.3,\n",
        "height_shift_range=0.3,\n",
        "rotation_range=30)\n",
        "\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "rescale = 1./255,\n",
        "horizontal_flip = True,\n",
        "fill_mode = \"nearest\",\n",
        "zoom_range = 0.3,\n",
        "width_shift_range = 0.3,\n",
        "height_shift_range=0.3,\n",
        "rotation_range=30)\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "TRAIN_DIR,\n",
        "target_size = (img_height, img_width),\n",
        "batch_size = batch_size, \n",
        "class_mode = \"categorical\")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "VAL_DIR,\n",
        "target_size = (img_height, img_width),\n",
        "batch_size = batch_size, \n",
        "class_mode = \"categorical\")\n",
        "\n",
        "\n",
        "\n",
        "# Save the model according to the conditions  \n",
        "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=10, verbose=1, mode='auto')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if (os.path.exists('model.tfl')):\n",
        "    model_final = load_model('model.tfl')\n",
        "else:\n",
        "    model_final.fit_generator(\n",
        "    train_generator,\n",
        "    samples_per_epoch=nb_train_samples,\n",
        "    nb_epoch=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    nb_val_samples=nb_validation_samples,\n",
        "    callbacks = [checkpoint, early])\n",
        "    model_final.save('model.tfl')\n",
        "\n",
        "# Train the model \n",
        "\n",
        "\n",
        "\n",
        "testing_pre = []\n",
        "\n",
        "for imagep in os.listdir(TEST_DIR):\n",
        "    image_path = os.path.join(TEST_DIR, imagep)\n",
        "    img = image.load_img(image_path, target_size=(img_width,img_height))\n",
        "    x = image.img_to_array(img)\n",
        "    x = np.expand_dims(x, axis = 0)\n",
        "    x = preprocess_input(x)\n",
        "    preds = model_final.predict(x)\n",
        "    print(imagep, preds, np.argmax(preds) + 1)\n",
        "\n",
        "    testing_pre.append([imagep,np.argmax(preds) + 1])\n",
        "\n",
        "Csv = pd.DataFrame(testing_pre)\n",
        "Csv.to_csv(\"subm1.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}